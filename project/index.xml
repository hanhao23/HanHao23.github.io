<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Projects | Han Hao Cog Psych</title>
    <link>https://hanhao23.github.io/project/</link>
      <atom:link href="https://hanhao23.github.io/project/index.xml" rel="self" type="application/rss+xml" />
    <description>Projects</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>hanhao23 © 2023</copyright><lastBuildDate>Wed, 09 Mar 2022 17:58:47 -0800</lastBuildDate>
    <image>
      <url>https://hanhao23.github.io/img/Titleboard.jpg</url>
      <title>Projects</title>
      <link>https://hanhao23.github.io/project/</link>
    </image>
    
    <item>
      <title>Intro to Item Response Modeling in R</title>
      <link>https://hanhao23.github.io/project/irttutorial/irt-tutorial-in-r-with-mirt-package/</link>
      <pubDate>Wed, 09 Mar 2022 17:58:47 -0800</pubDate>
      <guid>https://hanhao23.github.io/project/irttutorial/irt-tutorial-in-r-with-mirt-package/</guid>
      <description>
&lt;script src=&#34;https://hanhao23.github.io/project/irttutorial/irt-tutorial-in-r-with-mirt-package/index_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;overview&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Overview&lt;/h1&gt;
&lt;p&gt;The goal of this document is to introduce applications of R for item response theory (IRT) modeling. Specifically, this document is focused on introducing basic IRT analyses for beginners using the &lt;a href=&#34;https://cran.r-project.org/web/packages/mirt/mirt.pdf&#34;&gt;“mirt” package&lt;/a&gt; (Chalmers, 2012). It is not intended to be a full introduction to data analysis in R, nor to basic mathematics of item response theory. Instead, this tutorial will introduce the key concepts of IRT and important features of corresponding R packages/functions that facilitate IRT modeling for beginners. For a quick reference on the basics of IRT, please see the last section of recommended readings.&lt;/p&gt;
&lt;p&gt;In this tutorial, we will focus on unidimensional IRT models by presenting brief R examples using “mirt”. Specifically, we will talk about:&lt;br /&gt;
1. Key concepts in IRT;&lt;br /&gt;
2. Dichotomous, 1PL Model (Rasch Model);&lt;br /&gt;
3. Dichotomous, 2PL Model;&lt;br /&gt;
4. Polytomous, Generalized Partial Credit Model.&lt;/p&gt;
&lt;div id=&#34;install-and-load-packages&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Install and Load Packages&lt;/h2&gt;
&lt;p&gt;The first step is to make sure you have the R packages needed in this tutorial. We can obtain the “mirt” package from CRAN (using “install.packages(‘mirt’)”), or install the development version of the package from Github using the following codes:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;install.packages(&amp;#39;devtools&amp;#39;)
library(&amp;#39;devtools&amp;#39;)
install_github(&amp;#39;philchalmers/mirt&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We need the following packages in this tutorial:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse) # For data wrangling and basic visualizations
library(psych) # For descriptive stats and assumption checks
library(mirt) # IRT modeling&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;prepare-the-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Prepare the Data&lt;/h2&gt;
&lt;p&gt;The next step is to read in and prepare corresponding data files for the tutorial. The two data files we are using in this tutorial are available at here: &lt;a href=&#34;https://hanhao23.github.io/files/WMI_Read_Han_Wide.csv&#34;&gt;ReadingSpan&lt;/a&gt; and &lt;a href=&#34;https://hanhao23.github.io/files/WMI_Rot_Han_Wide.csv&#34;&gt;RotationSpan&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;These two datasets consist of item-level responses from 261 subjects on 2 complex span tasks: reading span and rotation span. In a complex span task, each item has a varying number of elements to process and memorize (item size). The responses in the two datasets are integer numbers that reflect the numbers of correctly recalled elements for each item. For the reading span task, there are 15 items presented across 3 blocks, with item sizes varied from 3 to 7. For the rotation span task, there are 12 items presented across 3 blocks, with item sizes varied from 2 to 5.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Conway et al. (2019) Data
wmir &amp;lt;- read.csv(&amp;quot;WMI_Read_Han_wide.csv&amp;quot;)[,-1]
wmirot &amp;lt;- read.csv(&amp;quot;WMI_Rot_Han_wide.csv&amp;quot;)[,-1]

colnames(wmir) &amp;lt;- c(&amp;quot;Subject&amp;quot;, 
                   &amp;quot;V1.3&amp;quot;, &amp;quot;V1.4&amp;quot;,&amp;quot;V1.5&amp;quot;, &amp;quot;V1.6&amp;quot;, &amp;quot;V1.7&amp;quot;,
                   &amp;quot;V2.3&amp;quot;, &amp;quot;V2.4&amp;quot;,&amp;quot;V2.5&amp;quot;, &amp;quot;V2.6&amp;quot;, &amp;quot;V2.7&amp;quot;,
                   &amp;quot;V3.3&amp;quot;, &amp;quot;V3.4&amp;quot;,&amp;quot;V3.5&amp;quot;, &amp;quot;V3.6&amp;quot;, &amp;quot;V3.7&amp;quot;)

colnames(wmirot) &amp;lt;- c(&amp;quot;Subject&amp;quot;, 
                   &amp;quot;S1.2&amp;quot;,&amp;quot;S1.3&amp;quot;, &amp;quot;S1.4&amp;quot;,&amp;quot;S1.5&amp;quot;, 
                   &amp;quot;S2.2&amp;quot;,&amp;quot;S2.3&amp;quot;, &amp;quot;S2.4&amp;quot;,&amp;quot;S2.5&amp;quot;, 
                   &amp;quot;S3.2&amp;quot;,&amp;quot;S3.3&amp;quot;, &amp;quot;S3.4&amp;quot;,&amp;quot;S3.5&amp;quot;)


# Wmi is the full dataset (N = 261)
wmi &amp;lt;- merge(wmir, wmirot, by = &amp;quot;Subject&amp;quot;)

head(wmir)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   Subject V1.3 V1.4 V1.5 V1.6 V1.7 V2.3 V2.4 V2.5 V2.6 V2.7 V3.3 V3.4 V3.5 V3.6
## 1       1    3    4    5    2    3    3    4    2    2    1    1    2    4    0
## 2       2    3    2    5    6    6    3    3    3    4    7    3    3    5    6
## 3       3    3    4    3    6    6    3    4    5    3    4    3    4    5    5
## 4       4    2    2    2    2    3    3    2    2    0    0    3    4    5    2
## 5       5    3    3    3    4    7    3    4    5    6    5    3    1    5    6
## 6       6    3    4    4    6    2    3    4    5    6    2    3    4    4    6
##   V3.7
## 1    3
## 2    7
## 3    2
## 4    1
## 5    7
## 6    7&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(wmirot)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   Subject S1.2 S1.3 S1.4 S1.5 S2.2 S2.3 S2.4 S2.5 S3.2 S3.3 S3.4 S3.5
## 1       1    2    1    0    0    0    3    1    0    1    1    0    0
## 2       2    2    2    1    1    2    3    2    2    2    2    1    1
## 3       3    2    1    4    1    2    3    4    1    1    2    0    3
## 4       4    2    2    3    1    2    0    1    1    2    2    3    4
## 5       5    2    3    4    5    2    3    4    4    2    3    4    2
## 6       7    2    3    0    2    2    3    4    3    2    1    2    1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Labels of the variables in the datasets indicate the corresponding block and item size of a specific item. For example, in the reading span dataset (wmir), the 5th column (“V1.6”) presents subjects’ responses on the item with 6 elements in the 1st block. Subject 1 recalled 2 of the 6 elements correctly.&lt;/p&gt;
&lt;p&gt;For a detail summary of the two complex span tasks, see &lt;a href=&#34;https://doi.org/10.3758/BF03196772&#34;&gt;Conway et al. (2005)&lt;/a&gt; and &lt;a href=&#34;https://doi.org/10.3758/s13421-021-01242-6&#34;&gt;Hao &amp;amp; Conway (2021)&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;key-concepts-in-item-response-theory&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Key Concepts in Item Response Theory&lt;/h1&gt;
&lt;p&gt;In this section we will briefly go over some key concepts and terms we will be using in this IRT tutorial.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Scale&lt;/strong&gt;: In this tutorial, a scale refers to any quantitative system that is designed to reflect an individual’s standing or level of ability on a latent construct or latent trait. A scale consists of multiple manifest items. These items can be questions in a survey, problems in a test, or trials in an experiment.&lt;br /&gt;
- &lt;strong&gt;Dichotomous IRT models&lt;/strong&gt; are applied to the items with two possible response categories (yes/no, correct/incorrect, etc.)&lt;br /&gt;
- &lt;strong&gt;Polytomous IRT models&lt;/strong&gt; are applicable if the items have more than two possible response categories (Likert-type response scale, questions with partial credits, etc.)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Dimensionality&lt;/strong&gt;: The number of distinguishable attributes that a scale reflect.&lt;br /&gt;
- For &lt;strong&gt;unidimensional IRT models&lt;/strong&gt;, it is assumed that the scale only reflect one dimension, such that all items in the scale are assumed to reflect a unitary latent trait.&lt;br /&gt;
- For &lt;strong&gt;multidimensional IRT models&lt;/strong&gt;, multiple dimensions can be reflected and estimated, such that the responses to the items in the scales are assumed to reflect properties of multiple latent traits.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Theta&lt;/strong&gt; (&lt;span class=&#34;math inline&#34;&gt;\(\Theta\)&lt;/span&gt;): the latent construct or trait that is measured by the scale. It represents individual differences on the latent construct being measured.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Information&lt;/strong&gt;: an index to characterize the precision of measurement of the item or the test on the underlying latent construct, with high information denoting more precision. In IRT, this index is represented as a function of persons at different levels, such that the information function reflects the range of trait level over which this item or this test is most useful for distinguishing among individuals.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Item Characteristic Curve&lt;/strong&gt; (ICC): AKA item trace curve. ICC represents an item response function that models the relationship between a person’s probability for endorsing an item category (&lt;em&gt;p&lt;/em&gt;) and the level on the construct measured by the scale (&lt;span class=&#34;math inline&#34;&gt;\(\Theta\)&lt;/span&gt;). For this purpose, the slope of the item characteristic curve is used to assess whether a specific item mean score has either a steeper curve (i.e., high value) or whether the item has a wider curve (i.e., low value) and, therefore, cannot adequately differentiate based on ability level.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Item Difficulty Parameter&lt;/strong&gt; (&lt;em&gt;b&lt;/em&gt;): the trait level on the latent scale where a person has a 50% chance of responding positively to the item. This definition of item difficulty applies to dichotomous models. For polytomous models, multiple threshold parameters (&lt;em&gt;d&lt;/em&gt;s) are estimated for an item so that the latent trait difference between and beyond the response categories are accounted for.&lt;br /&gt;
- Conceptually, the role of item difficulty parameters in an IRT model is equivalent to the intercepts of manifests in a latent factor model.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Item Discrimination Parameter&lt;/strong&gt; (&lt;em&gt;a&lt;/em&gt;): how accurately a given item can differentiate individuals based on ability level. describes the strength of an item’s discrimination between people with trait levels below and above the threshold &lt;em&gt;b&lt;/em&gt;. This parameter is also interpreted as describing how an item is related to the latent trait measured by the scale. In other words, the &lt;em&gt;a&lt;/em&gt; parameter for an item reflects the magnitude of item reliability (how much the item is contributing to total score variance).&lt;br /&gt;
- Conceptually, the role of item discrimination parameters in an IRT model is equivalent to the factor loadings of manifests in a latent factor model.&lt;/p&gt;
&lt;p&gt;The “mirt” package includes an interactive graphical interface (shiny app) to allow the parameters to be modified in an IRT exemplar item in real time. To facilitate understanding of these key concepts, you can run the line of code below in your R console to activate an interactive shiny app with examplar item trace plots for different types of IRT models.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;itemplot(shiny = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;unidimensional-dichotomous-irt-models&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Unidimensional Dichotomous IRT Models&lt;/h1&gt;
&lt;p&gt;In this section we will start with the basic unidimensional dichotomous model, in which all items are assumed to measure one latent trait, and the responses to items are all binary (0 = incorrect/no, 1 = correct/yes). We will use the rotation span dataset (wmirot) in this section. As aforementioned, the raw data present numbers of correctly recalled elements for each item, which are not binary responses. Thus, we need to re-score these items using a all-or-nothing unit scoring approach (Conway et al., 2005; p.775), such that only a response with all elements in the item correctly recalled is scored as “correct” (1), while all other responses are scored as “incorrect” (0). The “mirt” package has a built-in function,“key2binary”, to assign binary scores to items in a dataset based on a given answer key. Thus, we can transfer all the initial rotation span responses to a binary response scale.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dat1 &amp;lt;- key2binary(wmirot[,-1],
    key = c(2,3,4,5,2,3,4,5,2,3,4,5))
head(dat1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      S1.2 S1.3 S1.4 S1.5 S2.2 S2.3 S2.4 S2.5 S3.2 S3.3 S3.4 S3.5
## [1,]    1    0    0    0    0    1    0    0    0    0    0    0
## [2,]    1    0    0    0    1    1    0    0    1    0    0    0
## [3,]    1    0    1    0    1    1    1    0    0    0    0    0
## [4,]    1    0    0    0    1    0    0    0    1    0    0    0
## [5,]    1    1    1    1    1    1    1    0    1    1    1    0
## [6,]    1    1    0    0    1    1    1    0    1    0    0    0&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;assumption-checks&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Assumption Checks&lt;/h2&gt;
&lt;p&gt;Unidimensional IRT models assume that all items are measuring a single continuous latent variable. There are different ways to test the unidimensionality assumption. For example, we can estimate McDonald’s hierarchical Omega (&lt;span class=&#34;math inline&#34;&gt;\(\omega_h\)&lt;/span&gt;), which conceptually reflects percentage of variance in the scale scores accounted for by a general factor. An arbitrary cutoff of &lt;span class=&#34;math inline&#34;&gt;\(\omega_h\)&lt;/span&gt; &amp;gt; .70 is usually used as the rule of thumb. Unfortunately, the current data violated this assumption using this rule of thumb (&lt;span class=&#34;math inline&#34;&gt;\(\omega_h\)&lt;/span&gt; = .56), but for demonstration purpose, we went along with further analyses.&lt;/p&gt;
&lt;p&gt;For further details on unidimensionality, see &lt;a href=&#34;https://doi.org/10.1007/BF02289858&#34;&gt;Berge &amp;amp; Socan (2004)&lt;/a&gt; and &lt;a href=&#34;https://doi.org/10.1177/0146621605278814&#34;&gt;Zinbarg, Yovel, Revelle, &amp;amp; McDonald (2006)&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Another assumption of IRT is local independence, such that item responses are independent of one another. This assumption can be checked during the modeling fitting process by investigating the residuals and compute local dependence indices using the “residuals” function.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary(omega(dat1, plot = F))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Omega 
## omega(m = dat1, plot = F)
## Alpha:                 0.7 
## G.6:                   0.69 
## Omega Hierarchical:    0.56 
## Omega H asymptotic:    0.77 
## Omega Total            0.73 
## 
## With eigenvalues of:
##    g  F1*  F2*  F3* 
## 1.72 0.23 0.60 0.43 
## The degrees of freedom for the model is 33  and the fit was  0.07 
## The number of observations was  262  with Chi Square =  17.75  with prob &amp;lt;  0.99 
## 
## The root mean square of the residuals is  0.03 
## The df corrected root mean square of the residuals is  0.04 
## 
## RMSEA and the  0.9 confidence intervals are  0 0 0
## BIC =  -166.01Explained Common Variance of the general factor =  0.58 
## 
##  Total, General and Subset omega for each subset
##                                                  g  F1*  F2*  F3*
## Omega total for total scores and subscales    0.73 0.55 0.48 0.55
## Omega general for total scores and subscales  0.56 0.45 0.13 0.37
## Omega group for total scores and subscales    0.11 0.11 0.35 0.18&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;pl-rasch-model&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;1PL (Rasch) Model&lt;/h2&gt;
&lt;p&gt;We can start with a 1PL (Rasch) model, in which the discrimination parameters for all items are fixed to 1, while difficulty paramters are freely estimated in the model.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Model specification. Here we indicate that all columns in the dataset (1 to 12) measure the same latent factor (&amp;quot;rotation&amp;quot;)
uniDich.model1 &amp;lt;- mirt.model(&amp;quot;rotation = 1 - 12&amp;quot;)

# Model estimation. Here we indicate that we are estimating a Rasch model, and standard errors for parameters are estimated.
uniDich.result1 &amp;lt;- mirt::mirt(dat1, uniDich.model1, itemtype = &amp;quot;Rasch&amp;quot;, SE = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;model-and-item-fits&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Model and Item Fits&lt;/h3&gt;
&lt;p&gt;we can now investigate model fit statistics using the “M2” function, which provides the M2 index, the M2-based root mean square error of approximation (RMSEA), the standardized root mean square residual (SRMSR), and comparative fit index (CFI &amp;amp; TLI) to assess adequacy of model fit. A set of arbitrary cutoff values for the fit indices are provided here: RMSEA &amp;lt; .06; SRMSR &amp;lt; .08; CFI &amp;gt; .95; TLI &amp;gt; .95. Models with fit indices that saturate these cutoff values are commonly considered to have good fit. In this example, the non-significant M2 and all fit indices indicated great fit.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;M2(uniDich.result1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##             M2 df         p RMSEA RMSEA_5   RMSEA_95      SRMSR      TLI CFI
## stats 57.35425 65 0.7388255     0       0 0.02786493 0.05863013 1.016119   1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In IRT analyses, we can also assess how well each item fits the model. This is especially useful for item inspection and scale revision. The “itemfit” function provides S-X2 index as well as RMSEA values to assess the degree of item fit for each item. Non-significant S-X2 values and RMSEA &amp;lt; .06 are usually considered evidence of adequate fit for an item. In the current example, all items seem to fit the model well based on the indices.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;itemfit(uniDich.result1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    item   S_X2 df.S_X2 RMSEA.S_X2 p.S_X2
## 1  S1.2  7.250       5      0.042  0.203
## 2  S1.3 11.494       6      0.059  0.074
## 3  S1.4  7.566       6      0.032  0.272
## 4  S1.5  6.330       5      0.032  0.275
## 5  S2.2  4.483       6      0.000  0.612
## 6  S2.3  5.462       6      0.000  0.486
## 7  S2.4  5.275       6      0.000  0.509
## 8  S2.5  3.816       5      0.000  0.576
## 9  S3.2  1.528       6      0.000  0.958
## 10 S3.3  7.055       6      0.026  0.316
## 11 S3.4  5.081       6      0.000  0.533
## 12 S3.5  8.589       5      0.052  0.127&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Along with the model and item fits we can also check the local independence assumption using the “residuals” function. The following scripts provide the LD matrix as well as dfs and p-values for all LD indices. Large and significant LD indices are indicators of potential issues of local dependence and may require further attention.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;residuals(uniDich.result1, df.p = T)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Degrees of freedom (lower triangle) and p-values:
## 
##      S1.2  S1.3  S1.4  S1.5  S2.2  S2.3  S2.4  S2.5  S3.2  S3.3  S3.4  S3.5
## S1.2   NA 0.812 0.572 0.317 0.736 0.537 0.572 0.038 0.228 0.142 0.224 0.302
## S1.3    1    NA 0.441 0.326 0.221 0.176 0.827 0.232 0.553 0.508 0.160 0.778
## S1.4    1 1.000    NA 0.833 0.077 0.643 0.414 0.248 0.694 0.237 0.412 0.482
## S1.5    1 1.000 1.000    NA 0.486 0.734 0.575 0.144 0.600 0.677 0.879 0.553
## S2.2    1 1.000 1.000 1.000    NA 0.741 0.758 0.214 0.233 0.084 0.770 0.214
## S2.3    1 1.000 1.000 1.000 1.000    NA 0.265 0.505 0.261 0.126 0.194 0.222
## S2.4    1 1.000 1.000 1.000 1.000 1.000    NA 0.429 0.694 0.534 0.063 0.248
## S2.5    1 1.000 1.000 1.000 1.000 1.000 1.000    NA 0.523 0.187 0.866 0.086
## S3.2    1 1.000 1.000 1.000 1.000 1.000 1.000 1.000    NA 0.151 0.774 0.872
## S3.3    1 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000    NA 0.352 0.717
## S3.4    1 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000    NA 0.156
## S3.5    1 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000    NA
## 
## LD matrix (lower triangle) and standardized values:
## 
##       S1.2   S1.3   S1.4   S1.5   S2.2   S2.3   S2.4   S2.5   S3.2   S3.3
## S1.2    NA -0.015 -0.035  0.062 -0.021 -0.038 -0.035 -0.128  0.074 -0.091
## S1.3 0.057     NA  0.048  0.061  0.076  0.084  0.013  0.074  0.037  0.041
## S1.4 0.319  0.595     NA -0.013  0.109 -0.029 -0.051 -0.071 -0.024  0.073
## S1.5 1.002  0.966  0.045     NA -0.043 -0.021 -0.035 -0.090  0.032  0.026
## S2.2 0.114  1.498  3.120  0.486     NA  0.020  0.019  0.077  0.074  0.107
## S2.3 0.382  1.827  0.215  0.115  0.109     NA -0.069 -0.041  0.069  0.094
## S2.4 0.319  0.048  0.669  0.314  0.095  1.242     NA -0.049 -0.024 -0.038
## S2.5 4.286  1.428  1.335  2.136  1.547  0.444  0.626     NA  0.039 -0.082
## S3.2 1.453  0.351  0.155  0.274  1.425  1.265  0.155  0.408     NA  0.089
## S3.3 2.158  0.439  1.401  0.174  2.979  2.336  0.387  1.744  2.059     NA
## S3.4 1.479  1.976  0.673  0.023  0.085  1.684  3.445  0.029  0.082  0.866
## S3.5 1.067  0.080  0.495  0.352  1.547  1.491  1.335  2.953  0.026  0.132
##        S3.4   S3.5
## S1.2 -0.075 -0.064
## S1.3  0.087 -0.017
## S1.4 -0.051  0.043
## S1.5  0.009 -0.037
## S2.2  0.018  0.077
## S2.3  0.080 -0.075
## S2.4 -0.115 -0.071
## S2.5  0.010 -0.106
## S3.2 -0.018 -0.010
## S3.3  0.057 -0.022
## S3.4     NA -0.088
## S3.5  2.012     NA&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Other than the model fits and item fits, the “mirt” package also provides methods for calculating person fit statistics such as Zh statistics using the “personfit” function. In general, person fit statistics indicate how much a person’s responses on this test deviates from the the model prediction. See the “mirt” documentation and &lt;a href=&#34;https://doi.org/10.1111/j.2044-8317.1985.tb00817.x&#34;&gt;Drasgow, Levine, and Williams (1985)&lt;/a&gt; for further details.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(personfit(uniDich.result1))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      outfit    z.outfit     infit     z.infit         Zh
## 1 0.5429718  0.02890873 0.9234628 -0.06855285  0.3245494
## 2 0.3222275 -0.81981691 0.4792737 -1.50551325  1.2108896
## 3 1.3572362  0.68361018 1.6380112  1.45638097 -1.2704873
## 4 0.2944648 -0.60327679 0.4464911 -1.66830682  1.2602444
## 5 0.3693042 -0.15612318 0.6267169 -0.83751758  0.8026636
## 6 0.5580941 -0.53989282 0.8091663 -0.35965401  0.5450324&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;irt-paramters&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;IRT Paramters&lt;/h3&gt;
&lt;p&gt;We can obtain the item parameters from the model. As aforementioned, for a Rasch model, all discrimination parameters are fixed to 1, while difficulty parameters are freely estimated. In the output, the second column (“a”) contains the discrimination parameters and the third column (b) contains the difficulty parameters.&lt;/p&gt;
&lt;p&gt;In this example, we presented the IRT parameters using the conventional approach, such that a larger &lt;em&gt;b&lt;/em&gt; parameter indicates higher difficulty of an item. For example, the second item, S1.3 (item size 3 in the 1st block), has a b = -0.94. This indicates that, according to the model estimation, a person with ability level that is 0.94 standard deviation below the average has 50% of chance to answer this item (S1.3) correctly.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# IRT parameters from the estimated model. For this example, we are obtaining simplified output without SEs/CIs (simplify = TRUE) for conventional IRT parameters (IRTpar = TRUE).
coef(uniDich.result1,simplify = TRUE, IRTpar = TRUE)$items&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      a          b g u
## S1.2 1 -3.0033640 0 1
## S1.3 1 -0.9388653 0 1
## S1.4 1  0.5864289 0 1
## S1.5 1  2.4373369 0 1
## S2.2 1 -2.6395716 0 1
## S2.3 1 -1.4247025 0 1
## S2.4 1  0.5864289 0 1
## S2.5 1  2.3201998 0 1
## S3.2 1 -2.3398445 0 1
## S3.3 1 -0.9845155 0 1
## S3.4 1  0.3420016 0 1
## S3.5 1  2.3201998 0 1&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;visualizing-the-item-and-scale-characteristics&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Visualizing the Item and Scale Characteristics&lt;/h3&gt;
&lt;p&gt;We can visualize corresponding item and scale characteristics from the model by a variety of plot methods in “mirt”. The plots presents how items and the entire scale relate to the latent trait across the scale.&lt;br /&gt;
We can start with the item trace plots for the 12 items. The item trace plots visualize the probability of responding “1” to an item as a function of &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt;. According to the item trace plot of this example, the 3 items with item size 2 (S1.2,S2.2,S3.2) are relatively easy items, in which subjects with average ability (&lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt; = 0) are estimated to have about 80% to 90% of chance to answer correctly. On the other hand, the 3 items with size 5 are relatively hard items, in which subjects with average ability are estimated to have about only 10% to 20% of chance to answer correctly.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# In the function we cam specify the range of theta we&amp;#39;d like to visualize on the x axis of the plots. In this example we set it to -4 to 4 (4 SDs below and above average).
plot(uniDich.result1, type = &amp;quot;trace&amp;quot;, theta_lim = c(-4,4))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://hanhao23.github.io/project/irttutorial/irt-tutorial-in-r-with-mirt-package/index_files/figure-html/unidich%20Rasch%20ploting1-1.png&#34; width=&#34;672&#34; /&gt;
Other than the item trace plots, we can also look at the item information plots. Item information plots visualize how much “information” about the latent trait ability an item can provide. Conceptually, higher information implies less error of measure, and the peak of an item information curve is at the point of its b parameter. Thus, for easy items (such as the 3 items in the most left column below), little information are provided on subjects with high ability levels (because they will almost always answer correctly).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# We can specify the exact set of items we want to plot in the ploting function of mirt. Here we can also only visualize the 1st, 5th, and 9th item from the dataset by addin an argument &amp;quot;which.items = c(1,5,9)&amp;quot; in the function. This will make the function to only plot the 3 items with set size 2 in the task. Please feel free to give a try.
plot(uniDich.result1, type = &amp;quot;infotrace&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://hanhao23.github.io/project/irttutorial/irt-tutorial-in-r-with-mirt-package/index_files/figure-html/unidich%20Rasch%20ploting2-1.png&#34; width=&#34;672&#34; /&gt;
The “itemplot” function can provides more details regarding an item. This is an example that visualize the item trace plot of item 1 with confidence envelope.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;itemplot(uniDich.result1, item = 1, type = &amp;quot;trace&amp;quot;, CE = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://hanhao23.github.io/project/irttutorial/irt-tutorial-in-r-with-mirt-package/index_files/figure-html/unidich%20Rasch%20ploting3-1.png&#34; width=&#34;672&#34; /&gt;
Lastly, we can plot the information curve for the entire test. This is based on the sum of all item information curves and indicate how much information a test can provide at different latent trait levels based on the model. As aforementioned, high information indicate less error (low SE) of measurement. An ideal (but impossible) test would have high test information at all levels of latent trait levels.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(uniDich.result1, type = &amp;quot;infoSE&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://hanhao23.github.io/project/irttutorial/irt-tutorial-in-r-with-mirt-package/index_files/figure-html/unidich%20Rasch%20ploting4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;pl-model&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;2PL Model&lt;/h2&gt;
&lt;p&gt;We can also estimate a 2PL model on the same binary data of rotation span task. In a 2PL model, not only the item difficulty parameters (&lt;em&gt;b&lt;/em&gt;s) but also the item discrimination parameters (&lt;em&gt;a&lt;/em&gt;s) are estimated. Thus, a 2PL model assumes that different items vary in the ability to discriminate between persons with different latent trait levels.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;uniDich.model2 &amp;lt;- mirt.model(&amp;quot;rotation = 1 - 12&amp;quot;)

uniDich.result2 &amp;lt;- mirt::mirt(dat1, uniDich.model2, itemtype = &amp;quot;2PL&amp;quot;, SE = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;model-and-item-fits-1&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Model and Item Fits&lt;/h3&gt;
&lt;p&gt;Similarly, we can obtain corresponding statistics of the model such as model fit and item fit statistics. In this example, the overall model fit for the 2PL model is good.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;M2(uniDich.result2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##             M2 df         p RMSEA RMSEA_5   RMSEA_95      SRMSR      TLI CFI
## stats 40.90802 54 0.9054692     0       0 0.01662836 0.04004632 1.033223   1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Item fit statistics for this 2PL model indicate that the 2nd item (S1.3) may need further attention (significant S-X2 and large RMSEA).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;itemfit(uniDich.result2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    item   S_X2 df.S_X2 RMSEA.S_X2 p.S_X2
## 1  S1.2  1.607       6      0.000  0.952
## 2  S1.3 10.427       4      0.078  0.034
## 3  S1.4  6.922       5      0.038  0.227
## 4  S1.5  5.373       5      0.017  0.372
## 5  S2.2  4.646       5      0.000  0.461
## 6  S2.3  2.783       5      0.000  0.733
## 7  S2.4  3.550       6      0.000  0.737
## 8  S2.5  3.390       5      0.000  0.640
## 9  S3.2  1.839       5      0.000  0.871
## 10 S3.3  7.201       6      0.028  0.303
## 11 S3.4  6.146       6      0.010  0.407
## 12 S3.5  7.840       5      0.047  0.165&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;irt-parameters&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;IRT Parameters&lt;/h3&gt;
&lt;p&gt;We can obtain the item parameters from the model. For a 2PL model, both the item discrimination parameters and the item difficulty parameters are freely estimated. Similar to the output of the Rasch model, the second column (“a”) contains the discrimination parameters and the third column (b) contains the difficulty parameters. We can see that, unlike the Rasch model, now every item has a unique discrimination parameter.&lt;/p&gt;
&lt;p&gt;For a dichotomous 2PL model, the item discrimination parameters reflect how well an item could discriminate between persons with low and high ability/trait levels. Furthermore, the &lt;em&gt;a&lt;/em&gt; parameter also reflects the magnitude to which an item is related to the latent trait measured by the scale. Thus, a low discrimination parameter usually indicates potential issues for an item comparing to the general scale.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;coef(uniDich.result2,simplify = TRUE, IRTpar = TRUE)$items&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##              a          b g u
## S1.2 0.8196465 -3.2455844 0 1
## S1.3 1.7771645 -0.6171063 0 1
## S1.4 1.3365861  0.4431670 0 1
## S1.5 1.2963837  1.9023919 0 1
## S2.2 1.7058414 -1.7589910 0 1
## S2.3 1.3696765 -1.0753956 0 1
## S2.4 0.8589407  0.5905375 0 1
## S2.5 0.9387174  2.2626112 0 1
## S3.2 1.4477736 -1.7033180 0 1
## S3.3 1.5741235 -0.6888211 0 1
## S3.4 1.2459076  0.2655880 0 1
## S3.5 0.9445384  2.2521152 0 1&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;visualizing-the-item-and-scale-plots&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Visualizing the Item and Scale Plots&lt;/h3&gt;
&lt;p&gt;Comparing to the Rasch model, the estimated &lt;em&gt;a&lt;/em&gt; parameters in a 2PL model are also reflected in item trace plots, such that the differences in &lt;em&gt;a&lt;/em&gt;s are reflected by the changes in the steepness of the item trace curves. Higher &lt;em&gt;a&lt;/em&gt;s would be reflected as steeper item trace curves.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(uniDich.result2, type = &amp;quot;trace&amp;quot;, theta_lim = c(-4,4))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://hanhao23.github.io/project/irttutorial/irt-tutorial-in-r-with-mirt-package/index_files/figure-html/unidich%202PL%20ploting1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The freely estimated discrimination parameters are also reflected in the item information plots. As we can see, comparing to the Rasch model, the peaks of information curves are varying across items in the 2PL model.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(uniDich.result2, type = &amp;quot;infotrace&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://hanhao23.github.io/project/irttutorial/irt-tutorial-in-r-with-mirt-package/index_files/figure-html/unidich%202PL%20ploting2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;model-specifications&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Model Specifications&lt;/h2&gt;
&lt;p&gt;The model specification function of “mirt” provides arguments for further constraints in an IRT model and can be used for testing specific assumptions regarding the item characteristics.&lt;br /&gt;
For example, in the rotation span task, items with the exact same set size are designed in the exact same way. Thus, we consider the items with the same set size equivalent in their ability to discriminate persons with different ability levels. To estimate this model, we can specify the constraints in the model specification function. As is presented, in the function we specify an equal &lt;em&gt;a&lt;/em&gt; parameter for items 1, 5, &amp;amp; 9, which are labeled “S1.2”, “S2.2”, and “S3.2” in the dataset (these are the 3 items with set size 2); another equal &lt;em&gt;a&lt;/em&gt; for items 2, 6, &amp;amp; 1; another for items 3, 7, and 11; and another for items 4, 8, and 12.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;uniDich.model3 &amp;lt;- mirt.model(&amp;quot;rotation = 1 - 12
                             CONSTRAIN = (1,5,9,a1), (2,6,10,a1),(3,7,11,a1),(4,8,12,a1)&amp;quot;)

uniDich.result3 &amp;lt;- mirt::mirt(dat1, uniDich.model3, itemtype = &amp;quot;2PL&amp;quot;, SE = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The specification in constraints is reflected in the IRT parameters from this model. As we can observe, in the IRT parameters output, items with the same set sizes are estimated to have the exact same &lt;em&gt;a&lt;/em&gt; parameters. For all items with size 2, &lt;em&gt;a&lt;/em&gt; = 1.31, and for all items with size 3, &lt;em&gt;a&lt;/em&gt; = 1.55, etc. On the other hand, the &lt;em&gt;b&lt;/em&gt; parameters are still freely estimated regardless of the item size.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;coef(uniDich.result3,simplify = TRUE, IRTpar = TRUE)$items&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##             a          b g u
## S1.2 1.314847 -2.3120591 0 1
## S1.3 1.551951 -0.6626354 0 1
## S1.4 1.127870  0.4902232 0 1
## S1.5 1.036344  2.2120724 0 1
## S2.2 1.314847 -2.0337955 0 1
## S2.3 1.551951 -1.0029799 0 1
## S2.4 1.127870  0.4902232 0 1
## S2.5 1.036344  2.1036240 0 1
## S3.2 1.314847 -1.8044209 0 1
## S3.3 1.551951 -0.6946542 0 1
## S3.4 1.127870  0.2815835 0 1
## S3.5 1.036344  2.1036240 0 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can also do model comparisons for nested models with different constraints. For example, we can test the difference between this constrained model and the previous 2PL model without any constraints on discrimination. This is similar to a model comparison based on chi-squared statistics for nested SEM models. As we can see, results indicate that the two models are not significantly different from each other, &lt;span class=&#34;math inline&#34;&gt;\(\Delta\chi^2\)&lt;/span&gt;(8) = 8.68, &lt;em&gt;p&lt;/em&gt; = .37.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;anova(uniDich.result2,uniDich.result3)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Model 1: mirt::mirt(data = dat1, model = uniDich.model3, itemtype = &amp;quot;2PL&amp;quot;, 
##     SE = TRUE)
## Model 2: mirt::mirt(data = dat1, model = uniDich.model2, itemtype = &amp;quot;2PL&amp;quot;, 
##     SE = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##        AIC     AICc    SABIC       HQ      BIC    logLik    X2  df    p
## 1 2941.329 2943.549 2947.695 2964.276 2998.422 -1454.664   NaN NaN  NaN
## 2 2948.644 2953.708 2958.194 2983.065 3034.285 -1450.322 8.684   8 0.37&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;unidimensional-polytomous-irt-model&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Unidimensional Polytomous IRT Model&lt;/h1&gt;
&lt;p&gt;In the previous section we have conducted dichotomous IRT analyses on the rotation span task dataset with binary responses. However, the initial rotation span dataset consist of numbers of correctly recalled elements for each item. In other words, each item actually has more than two possible response categories that are at least ordinal. For example, for an item with set size 2 (2 elements in the item), there are 3 possible response outcomes: 0, 1, and 2. Thus, we could fit and assess a polytomous IRT model to this type of measures, such as partial-scored tests and Likert-type surveys.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dat2 &amp;lt;- as.matrix(wmirot[,-1])
head(dat2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      S1.2 S1.3 S1.4 S1.5 S2.2 S2.3 S2.4 S2.5 S3.2 S3.3 S3.4 S3.5
## [1,]    2    1    0    0    0    3    1    0    1    1    0    0
## [2,]    2    2    1    1    2    3    2    2    2    2    1    1
## [3,]    2    1    4    1    2    3    4    1    1    2    0    3
## [4,]    2    2    3    1    2    0    1    1    2    2    3    4
## [5,]    2    3    4    5    2    3    4    4    2    3    4    2
## [6,]    2    3    0    2    2    3    4    3    2    1    2    1&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;generalized-partial-credit-model&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Generalized Partial Credit Model&lt;/h2&gt;
&lt;p&gt;In this section, we will apply the generalized partial credit model (GPCM; &lt;a href=&#34;https://doi.org/10.1002/j.2333-8504.1992.tb01436.x&#34;&gt;Muraki, 1992&lt;/a&gt;) to the rotation span data. As a polytomous model, GPCM estimates one item threshold parameter for &lt;strong&gt;each response category&lt;/strong&gt; in an item instead of one difficulty parameter for an item. Further more, GPCM assumes an unique item discrimination parameter for each item instead of assuming a unitary reliability across items (like the Rasch model).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;unipoly.model1 &amp;lt;- mirt.model(&amp;quot;rotation = 1 - 12&amp;quot;)

unipoly.result1 &amp;lt;- mirt::mirt(dat2, uniDich.model2, itemtype = &amp;quot;gpcm&amp;quot;, SE = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;model-and-item-fits-2&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Model and Item Fits&lt;/h3&gt;
&lt;p&gt;Similarly, we can obtain corresponding statistics of the model such as model fit and item fit statistics. In this example, the overall model fit and all item fits for the GPCM model are good.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;M2(unipoly.result1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##             M2 df         p RMSEA RMSEA_5   RMSEA_95      SRMSR      TLI CFI
## stats 23.66605 24 0.4808204     0       0 0.04927329 0.04771738 1.005052   1&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;itemfit(unipoly.result1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    item   S_X2 df.S_X2 RMSEA.S_X2 p.S_X2
## 1  S1.2 15.329      11      0.039  0.168
## 2  S1.3 46.224      32      0.041  0.050
## 3  S1.4 43.506      48      0.000  0.657
## 4  S1.5 44.058      58      0.000  0.912
## 5  S2.2 20.725      13      0.048  0.079
## 6  S2.3 30.299      26      0.025  0.255
## 7  S2.4 48.715      50      0.000  0.525
## 8  S2.5 71.664      61      0.026  0.165
## 9  S3.2 13.519      17      0.000  0.701
## 10 S3.3 20.588      32      0.000  0.940
## 11 S3.4 52.075      51      0.009  0.432
## 12 S3.5 63.890      63      0.007  0.445&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;irt-parameters-1&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;IRT Parameters&lt;/h3&gt;
&lt;p&gt;For a GPCM model, the item discrimination parameters and the item threshold parameters are freely estimated. In a GPCM model, the item threshold parameter is defined as the trait level in which one has an equal probability of choosing the &lt;em&gt;k&lt;/em&gt;th response category over the &lt;em&gt;k-1&lt;/em&gt;th category in an item. When choosing between the &lt;em&gt;k&lt;/em&gt;th and the &lt;em&gt;k-1&lt;/em&gt;th category, subjects with trait levels higher than that threshold are more likely to approach the &lt;em&gt;k&lt;/em&gt;th, while subjects with trait levels lower than that threshold are more likely to approach the &lt;em&gt;k-1&lt;/em&gt;th.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;coef(unipoly.result1,simplify = TRUE, IRTpars = TRUE)$items&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##              a         b1          b2         b3        b4          b5
## S1.2 0.6354780 -2.4238753 -4.50115962         NA        NA          NA
## S1.3 0.8367055 -1.5716066 -0.89123631 -1.8001978        NA          NA
## S1.4 0.5989767 -1.8187952 -0.50303114  0.5399410 -1.379714          NA
## S1.5 0.4660780 -0.7725926 -0.02659485  0.5368132  1.745108  0.07050096
## S2.2 1.0176875 -1.8131900 -2.77011850         NA        NA          NA
## S2.3 0.8606748 -2.3689773 -0.88851301 -2.2413670        NA          NA
## S2.4 0.4985639 -1.6434258 -0.70470153 -0.3802990 -1.060266          NA
## S2.5 0.4158617 -0.5284300 -1.00120923  1.5317726  1.243526 -0.09643630
## S3.2 0.8508984 -1.3638275 -3.01408652         NA        NA          NA
## S3.3 0.8038394 -1.7838070 -1.03577722 -1.8430426        NA          NA
## S3.4 0.5793661 -0.6192944 -0.94635296  0.0811653 -1.540936          NA
## S3.5 0.4046533 -0.5014941 -0.68390425  0.3561937  1.278277  0.42457494&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In this example, the function utilizes the conventional IRT parameterization. In the conventional parameterization, for an item of size &lt;em&gt;p&lt;/em&gt;, GPCM estimates &lt;em&gt;p&lt;/em&gt; item threshold parameters for each of the categories (from “&lt;em&gt;b_1&lt;/em&gt;” for partial scores of 0 and 1 to “&lt;em&gt;b_p&lt;/em&gt;” for partial scores p-1 and p), and 1 item discrimination parameter for the item. The second column (“&lt;em&gt;a_1&lt;/em&gt;”) contains the discrimination parameters and the later columns (“&lt;em&gt;b_1&lt;/em&gt;” to “&lt;em&gt;b_5&lt;/em&gt;”) contain all the threshold parameters.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;visualizing-the-item-and-scale-plots-1&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Visualizing the Item and Scale Plots&lt;/h3&gt;
&lt;p&gt;Similar to the dichotomous 2PL model, the estimated &lt;em&gt;a&lt;/em&gt; parameters in a GPCM model are reflected in item trace plots, such that the differences in &lt;em&gt;a&lt;/em&gt;s are reflected by the changes in the steepness of the item trace curves. Higher &lt;em&gt;a&lt;/em&gt;s would be reflected as steeper item trace curves. On the other hand, the estimated &lt;em&gt;b&lt;/em&gt; parameters in a GPCM model are reflected as (x-axis values for) the adjacent points between trace curves for different categories. For example, for Item S3.2, the current GPCM model estimated two threshold parameters: b1 = -1.36 (the adjacent point between curve P1 and P2) and b2 = -3.01 (the adjacent point between curve P2 and P3).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(unipoly.result1, type = &amp;quot;trace&amp;quot;, theta_lim = c(-4,4))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://hanhao23.github.io/project/irttutorial/irt-tutorial-in-r-with-mirt-package/index_files/figure-html/unipoly%202PL%20ploting1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Similar to the dichotomous 2PL model, the freely estimated discrimination parameters are also reflected in the item information plots.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(unipoly.result1, type = &amp;quot;infotrace&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://hanhao23.github.io/project/irttutorial/irt-tutorial-in-r-with-mirt-package/index_files/figure-html/unipoly%202PL%20ploting2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;individual-scoring&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Individual Scoring&lt;/h3&gt;
&lt;p&gt;Based on an estimated model, we can also estimate the individual latent trait scores. Conceptually, the estimated latent trait scores are similar to factor scores estimated in CFAs.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;est.theta &amp;lt;- as.data.frame(fscores(unipoly.result1))
head(est.theta)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##     rotation
## 1 -1.9429664
## 2 -0.7051405
## 3 -0.5498356
## 4 -0.6928339
## 5  1.4039574
## 6 -0.3787596&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;est.theta %&amp;gt;% 
  ggplot(aes(x=rotation)) +
    geom_histogram(aes(y=..density..),
                   binwidth=.1,
                   colour=&amp;quot;black&amp;quot;, fill=&amp;quot;white&amp;quot;) +
    geom_density(alpha=.2, fill=&amp;quot;aquamarine2&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://hanhao23.github.io/project/irttutorial/irt-tutorial-in-r-with-mirt-package/index_files/figure-html/unipoly%202PL%20scoring-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Formative Model in Lavaan</title>
      <link>https://hanhao23.github.io/project/formfactor/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      <guid>https://hanhao23.github.io/project/formfactor/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Data Analysis with Repeat Measures in Generalized Mixed Effects Model</title>
      <link>https://hanhao23.github.io/project/glmm/</link>
      <pubDate>Thu, 27 Apr 1916 00:00:00 +0000</pubDate>
      <guid>https://hanhao23.github.io/project/glmm/</guid>
      <description>
&lt;script src=&#34;https://hanhao23.github.io/project/glmm/index_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;package-and-data-preparation&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Package and Data Preparation&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(psych) # For descriptives and ANOVA, and else
library(ez) # For ANOVA
library(tidyverse) # This is a collection of packages for data wrangling and visualizing
library(Rmisc)
library(reshape2) # For reorganizing data
#library(lsr)
library(lme4) # For generalized linear mixed effect model
library(lmerTest) # For p values in generalized linear mixed effect model
#library(emmeans)
#library(dplyr)
#library(forcats)
library(DescTools)
#library(SuppDists)
library(effsize)
library(ggpubr)
#library(MVN)
library(r2glmm)

dat &amp;lt;- read.csv(&amp;quot;Demo Data Das.csv&amp;quot;) # Read in the csv data&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;data-forging&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Data forging&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# A quick look at the first several rows of the data. This is the wide format in which each row contains all information from one individual.
head(dat)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   X D1S D2S D3S D1D D2D D3D     Speed         WMC
## 1 1   6   6  10   3   4   2  52.57522  0.86260286
## 2 2  10   6   8   4   5   1  87.14825  0.41562595
## 3 3   8  10   9   5   2   3  65.23954 -1.74653932
## 4 4  10   9   9   3   2   3 106.95063 -0.03135097
## 5 5   7   9   9   3   3   4  89.83073  1.50946304
## 6 6   7   8   2   5   6   4 161.63888  0.75637916&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# This function melt a wide-format data into long-formant in which each row contains information from one trial.
dat2 &amp;lt;- melt(dat, measure.vars = c(&amp;quot;D1S&amp;quot;,&amp;quot;D2S&amp;quot;,&amp;quot;D3S&amp;quot;, &amp;quot;D1D&amp;quot;,&amp;quot;D2D&amp;quot;,&amp;quot;D3D&amp;quot;), variable.name = &amp;quot;Condition&amp;quot;, value.name = &amp;quot;Score&amp;quot;)

# Spliting the string variable &amp;quot;condition&amp;quot; into two seperate (repeated measure) variables
dat3 &amp;lt;- separate(dat2, Condition, sep = 2, into = c(&amp;quot;Factor1&amp;quot;,&amp;quot;Factor2&amp;quot;), remove = TRUE)

# I recoded the ID variable to a factor (for the ANOVA analyses, otherwise R will treat it as a DV)
dat3$X &amp;lt;- as.factor(dat3$X)
# Factor 1 has 3 levels and I took out the 3rd level (otherwise I will have to have 2 dummy-coded variables for Factor1 in regression).
dat3Final &amp;lt;-subset(dat3, Factor1 != &amp;quot;D3&amp;quot;)

# Now the current data are formatted as a &amp;#39;perfect&amp;#39; long format
head(dat3)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   X     Speed         WMC Factor1 Factor2 Score
## 1 1  52.57522  0.86260286      D1       S     6
## 2 2  87.14825  0.41562595      D1       S    10
## 3 3  65.23954 -1.74653932      D1       S     8
## 4 4 106.95063 -0.03135097      D1       S    10
## 5 5  89.83073  1.50946304      D1       S     7
## 6 6 161.63888  0.75637916      D1       S     7&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;anova-with-ezanova-package&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;ANOVA with “ezANOVA” Package&lt;/h3&gt;
&lt;p&gt;This package gives 3 options for us to calculate Sums of Squares, and the following note is copied directly from their documentation:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Numeric value (either 1, 2 or 3) specifying the Sums of Squares “type” to employ when data are unbalanced (eg. when group sizes differ). type = 2 is the default because this will yield identical ANOVA results as type = 1 when data are balanced but type = 2 will additionally yield various assumption tests where appropriate. When data are unbalanced, users are warned that they should give special consideration to the value of type. type=3 will emulate the approach taken by popular commercial statistics packages like SAS and SPSS, but users are warned that this approach is not without criticism.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Type 1
ezANOVA(dat3Final, dv = .(Score), wid = .(X), within = .(Factor1, Factor2), type = 1, return_aov = TRUE, detailed = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $ANOVA
##            Effect DFn DFd       SSn      SSd           F            p p&amp;lt;.05
## 1         Factor1   1  89   0.40000  94.1000   0.3783209 5.400727e-01      
## 2         Factor2   1  89 846.40000 530.1000 142.1045086 3.864254e-20     *
## 3 Factor1:Factor2   1  89  20.54444 133.9556  13.6497180 3.798565e-04     *
##           ges
## 1 0.000527318
## 2 0.527498096
## 3 0.026383003
## 
## $aov
## 
## Call:
## aov(formula = formula(aov_formula), data = data)
## 
## Grand Mean: 6.038889
## 
## Stratum 1: X
## 
## Terms:
##                 Residuals
## Sum of Squares   217.9556
## Deg. of Freedom        89
## 
## Residual standard error: 1.564909
## 
## Stratum 2: X:Factor1
## 
## Terms:
##                 Factor1 Residuals
## Sum of Squares      0.4      94.1
## Deg. of Freedom       1        89
## 
## Residual standard error: 1.028253
## 1 out of 2 effects not estimable
## Estimated effects are balanced
## 
## Stratum 3: X:Factor2
## 
## Terms:
##                 Factor2 Residuals
## Sum of Squares    846.4     530.1
## Deg. of Freedom       1        89
## 
## Residual standard error: 2.440529
## 1 out of 2 effects not estimable
## Estimated effects are balanced
## 
## Stratum 4: X:Factor1:Factor2
## 
## Terms:
##                 Factor1:Factor2 Residuals
## Sum of Squares         20.54444 133.95556
## Deg. of Freedom               1        89
## 
## Residual standard error: 1.226833
## Estimated effects are balanced&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Type 3
ezANOVA(dat3Final, dv = .(Score), wid = .(X), within = .(Factor1, Factor2), type = 3, return_aov = TRUE, detailed = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $ANOVA
##            Effect DFn DFd         SSn      SSd            F            p p&amp;lt;.05
## 1     (Intercept)   1  89 13128.54444 217.9556 5360.9115518 2.558857e-81     *
## 2         Factor1   1  89     0.40000  94.1000    0.3783209 5.400727e-01      
## 3         Factor2   1  89   846.40000 530.1000  142.1045086 3.864254e-20     *
## 4 Factor1:Factor2   1  89    20.54444 133.9556   13.6497180 3.798565e-04     *
##            ges
## 1 0.9307951118
## 2 0.0004096216
## 3 0.4644141782
## 4 0.0206133848
## 
## $aov
## 
## Call:
## aov(formula = formula(aov_formula), data = data)
## 
## Grand Mean: 6.038889
## 
## Stratum 1: X
## 
## Terms:
##                 Residuals
## Sum of Squares   217.9556
## Deg. of Freedom        89
## 
## Residual standard error: 1.564909
## 
## Stratum 2: X:Factor1
## 
## Terms:
##                 Factor1 Residuals
## Sum of Squares      0.4      94.1
## Deg. of Freedom       1        89
## 
## Residual standard error: 1.028253
## 1 out of 2 effects not estimable
## Estimated effects are balanced
## 
## Stratum 3: X:Factor2
## 
## Terms:
##                 Factor2 Residuals
## Sum of Squares    846.4     530.1
## Deg. of Freedom       1        89
## 
## Residual standard error: 2.440529
## 1 out of 2 effects not estimable
## Estimated effects are balanced
## 
## Stratum 4: X:Factor1:Factor2
## 
## Terms:
##                 Factor1:Factor2 Residuals
## Sum of Squares         20.54444 133.95556
## Deg. of Freedom               1        89
## 
## Residual standard error: 1.226833
## Estimated effects are balanced&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;anova-with-aov-function&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;ANOVA with “aov” Function&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;AnovaModel &amp;lt;- aov(Score ~ Factor1*Factor2 + Error(X/(Factor1*Factor2)), data = dat3)
summary(AnovaModel)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Error: X
##           Df Sum Sq Mean Sq F value Pr(&amp;gt;F)
## Residuals 89  255.7   2.873               
## 
## Error: X:Factor1
##            Df Sum Sq Mean Sq F value  Pr(&amp;gt;F)    
## Factor1     2  47.69  23.846   17.19 1.5e-07 ***
## Residuals 178 246.97   1.387                    
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Error: X:Factor2
##           Df Sum Sq Mean Sq F value Pr(&amp;gt;F)    
## Factor2    1 1822.3    1822   226.6 &amp;lt;2e-16 ***
## Residuals 89  715.7       8                   
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Error: X:Factor1:Factor2
##                  Df Sum Sq Mean Sq F value  Pr(&amp;gt;F)    
## Factor1:Factor2   2  120.2   60.08   36.64 4.7e-14 ***
## Residuals       178  291.8    1.64                    
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Effect sizes
EtaSq(AnovaModel, type = 1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                     eta.sq eta.sq.part eta.sq.gen
## Factor1         0.01362519   0.1618527 0.03061484
## Factor2         0.52062030   0.7180224 0.54684319
## Factor1:Factor2 0.03432802   0.2916487 0.07370411&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;anova-plot&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;ANOVA Plot&lt;/h3&gt;
&lt;p&gt;This is just a quick visualization of the condition differences.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;DescribeSummary &amp;lt;- summarySE(dat3Final, measurevar = &amp;quot;Score&amp;quot;, groupvars = c(&amp;quot;Factor1&amp;quot;,&amp;quot;Factor2&amp;quot;))

pd = position_dodge(0.9)

ggplot(DescribeSummary, aes(x=Factor1, y=Score, fill=Factor2)) + 
  geom_errorbar(aes(ymin=Score-se, 
                    ymax=Score+se), 
                width=.2, size=1, position=pd) +
  geom_bar(position = &amp;quot;dodge&amp;quot;, stat = &amp;quot;identity&amp;quot;, alpha = 0.7) +
  coord_cartesian(ylim=c(2,9))+
  theme_classic() +
  scale_fill_grey(start = .1, end = .8) +
  theme(
    axis.title.y = element_text(vjust= 1.8),
    axis.title.x = element_text(vjust= -0.5),
    axis.title = element_text(face = &amp;quot;bold&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://hanhao23.github.io/project/glmm/index_files/figure-html/ANOVAViz-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;generalized-linear-mixed-effect-model&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Generalized Linear Mixed Effect Model&lt;/h3&gt;
&lt;p&gt;I just attached the scripts that I used in my own project, but I also just started to use GLMM so there is still a huge lot I am not 100% clear about the analysis.&lt;br /&gt;
Here I dummy-coded the two factors, and specify the random intercept without considering any indivdiual level effect of the fectors (nothing except (1|X) in the “random term” in the formula).&lt;/p&gt;
&lt;p&gt;This is some data I fictioned so here it seems the fitted model “lmmodel1” is singular: there might be too few variance in at least one effect, or it could also be a miss specification of the model.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Dummy coding
dat3Final$F1Dummy &amp;lt;- dummy(dat3Final$Factor1,&amp;quot;D2&amp;quot;)
dat3Final$F2Dummy &amp;lt;- dummy(dat3Final$Factor2,&amp;quot;S&amp;quot;)

# Model specification and estimation
lmmodel1 &amp;lt;- lmer(Score ~ WMC*F1Dummy*F2Dummy + (1|X), data = dat3Final, REML = FALSE)
summary(lmmodel1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Linear mixed model fit by maximum likelihood . t-tests use Satterthwaite&amp;#39;s
##   method [lmerModLmerTest]
## Formula: Score ~ WMC * F1Dummy * F2Dummy + (1 | X)
##    Data: dat3Final
## 
##      AIC      BIC   logLik deviance df.resid 
##   1395.6   1434.5   -687.8   1375.6      350 
## 
## Scaled residuals: 
##     Min      1Q  Median      3Q     Max 
## -3.3869 -0.7239  0.1256  0.7391  1.8144 
## 
## Random effects:
##  Groups   Name        Variance  Std.Dev. 
##  X        (Intercept) 9.840e-19 9.919e-10
##  Residual             2.673e+00 1.635e+00
## Number of obs: 360, groups:  X, 90
## 
## Fixed effects:
##                      Estimate Std. Error        df t value Pr(&amp;gt;|t|)    
## (Intercept)           4.77778    0.17234 360.00000  27.722  &amp;lt; 2e-16 ***
## WMC                  -0.06142    0.21428 360.00000  -0.287  0.77458    
## F1Dummy              -0.54444    0.24373 360.00000  -2.234  0.02611 *  
## F2Dummy               2.58889    0.24373 360.00000  10.622  &amp;lt; 2e-16 ***
## WMC:F1Dummy           0.13748    0.30304 360.00000   0.454  0.65035    
## WMC:F2Dummy           0.35115    0.30304 360.00000   1.159  0.24733    
## F1Dummy:F2Dummy       0.95556    0.34469 360.00000   2.772  0.00586 ** 
## WMC:F1Dummy:F2Dummy  -0.04944    0.42857 360.00000  -0.115  0.90823    
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Correlation of Fixed Effects:
##             (Intr) WMC    F1Dmmy F2Dmmy WMC:F1Dm WMC:F2 F1D:F2
## WMC          0.000                                            
## F1Dummy     -0.707  0.000                                     
## F2Dummy     -0.707  0.000  0.500                              
## WMC:F1Dummy  0.000 -0.707  0.000  0.000                       
## WMC:F2Dummy  0.000 -0.707  0.000  0.000  0.500                
## F1Dmmy:F2Dm  0.500  0.000 -0.707 -0.707  0.000    0.000       
## WMC:F1D:F2D  0.000  0.500  0.000  0.000 -0.707   -0.707  0.000
## optimizer (nloptwrap) convergence code: 0 (OK)
## boundary (singular) fit: see ?isSingular&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Looking at the group effects
anova(lmmodel1, type = 3)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Type III Analysis of Variance Table with Satterthwaite&amp;#39;s method
##                      Sum Sq Mean Sq NumDF DenDF  F value    Pr(&amp;gt;F)    
## WMC                   0.220   0.220     1   360   0.0821  0.774576    
## F1Dummy              13.339  13.339     1   360   4.9898  0.026111 *  
## F2Dummy             301.606 301.606     1   360 112.8248 &amp;lt; 2.2e-16 ***
## WMC:F1Dummy           0.550   0.550     1   360   0.2058  0.650347    
## WMC:F2Dummy           3.589   3.589     1   360   1.3427  0.247334    
## F1Dummy:F2Dummy      20.544  20.544     1   360   7.6853  0.005857 ** 
## WMC:F1Dummy:F2Dummy   0.036   0.036     1   360   0.0133  0.908226    
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Effect sizes. I googled and found this R2beta people report but I am still trying to understand what it really means.
r2beta(model = lmmodel1, partial = T)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                Effect   Rsq upper.CL lower.CL
## 1               Model 0.487    0.555    0.426
## 4             F2Dummy 0.245    0.321    0.175
## 7     F1Dummy:F2Dummy 0.022    0.061    0.002
## 3             F1Dummy 0.014    0.049    0.000
## 6         WMC:F2Dummy 0.004    0.028    0.000
## 5         WMC:F1Dummy 0.001    0.017    0.000
## 2                 WMC 0.000    0.016    0.000
## 8 WMC:F1Dummy:F2Dummy 0.000    0.015    0.000&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;glmm-visualization&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;GLMM Visualization&lt;/h3&gt;
&lt;p&gt;I use these codes to visualize my GLMM data. It should be of help to break the conditions down and visualize the correlations beween the continous predictor and the outcome (performance) by unique conditions.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;split_plot &amp;lt;- ggplot(aes(WMC, Score), data = dat3Final) + 
  geom_point() + 
  stat_smooth(method = &amp;quot;lm&amp;quot;, col = &amp;quot;red&amp;quot;, size = 2, alpha = 0.3) +
  facet_wrap(~ Factor1*Factor2) + 
  theme_classic2() + 
  xlab(&amp;quot;WMC&amp;quot;) + 
  ylab(&amp;quot;Test score&amp;quot;)
split_plot&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://hanhao23.github.io/project/glmm/index_files/figure-html/GLMMViz-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
